{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# The battle of the Neighborhoods (Part 1 only)\n\nAs part of the Coursera IBM Data Science Professional Specialization, this report discribes a recommender system for location data\n\n## Problem Discription\n\nWhenever I am coming to a new city, I have a hard time to access which location I should select. This is true for my as a tourist as well as if I am (like recently) moved away to a new location.\nTypically, I as a user know my own preferences and what I expect from an area. For instance, my personal perference is a lively region with a lot of shops, bars and recreational areas. A got medical system with many doctors may not be of much importance for me. Hence, it would be nice to get, based on a set of preferences, a recomondation for which area in a city to go for.\n\nThis is exactly what the discribed service does!\n\n\n\n## Data and Approach\n\n### Data\nIn order to recommend a certain area of a city, two main types of data is needed:\n\n1. *User Preferences rating a set of attributes*\n\n    The user preferences are taken from a user persona, which is the input to the approach. I as a user have to enter that the importance for e.g. a Bar is 5 and so on.\n\n2. *Location Data discribing the quality of a region with respect to the set of of attributes*\n\n    The fundamentals of the location data is retrieved usering the FourSquareAPI for a given area. Using the API, all  entries in a circular area around the location center are collected and the number of entries for the various categories are counted.  \n    \n### Approach\n\nIn order to allow a recommondation, the collected data is preprocessed.\n\nAt first, an area grid is created forming a regular grid of locations matching the size of the target size. After the locational data for each gird entry is created, the locational data is preprocessed by normalizing the number of entries for each category using the MinMaxScaler. This is in order to avoid the different scales in the entries, while some elements like Coffee Shops tend to have a high occurance, other enties like specialized restaurants have fewer entries. Hence, in order to compare the scale, the numbers are normalized for each categories over all grid cells.\n\nThan, the normalized data can be used in a recommender system by multiplying the user profile with the noramlized gird data.\n\nFinally, a preference score is obtained for each grid entry, and displayed on a map using folium.\n  \n\n## Results\n\nA full discussion of results is done in the second part of the Capstone project. For an example on the resulting map, please refer to \nhttps://eu-gb.dataplatform.cloud.ibm.com/analytics/notebooks/v2/0ab39b8b-4476-47e2-8724-5d8a8f29c3bc/view?access_token=913ce965121ab774982c261121215d913c317f90925f4d01f3ce5b5499f3f04b  .\n\n## Discussion\n\nDone in the second part of the Capstone project\n\n\n## Conclusions\n\nDone in the second part of the Capstone project\n\n", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.5", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}